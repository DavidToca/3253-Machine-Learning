{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1- PCA MNIST Student Practice (class).ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"H9pphNqqFve-"},"source":["# Objective:\n","\n","### Use MNIST dataset and apply PCA to find out the impact on the model training time and also model performance\n","### The work is taken from https://github.com/mGalarnyk/Python_Tutorials/blob/master/Sklearn/PCA/PCA_to_Speed-up_Machine_Learning_Algorithms.ipynb"]},{"cell_type":"code","metadata":{"id":"RkbQkRkNFjn2"},"source":["# Setup\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import StandardScaler\n","from sklearn import metrics\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import numpy as np\n","from sklearn.datasets import fetch_openml\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iNXDI6VJGNTq"},"source":["#Download and Load the Data\n"]},{"cell_type":"code","metadata":{"id":"sc9tKI0gF5_G"},"source":["from sklearn.datasets import fetch_openml\n","#get MNIST data\n","mnist = fetch_openml('mnist_784', version=1, cache=True)\n","mnist.target = mnist.target.astype(np.int8) # fetch_openml() returns targets as strings\n","\n","X, y = mnist[\"data\"], mnist[\"target\"]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2zVF3pvMHiAJ"},"source":["# Split data into train/test"]},{"cell_type":"code","metadata":{"id":"FxVFDOX_F-iw"},"source":["# Write a code to split your dataset into 80/20 dataset\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-r5taD09Hvh6"},"source":["# View Data Dimension"]},{"cell_type":"code","metadata":{"id":"iY_oQehrHlWa"},"source":["X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2e-0MowUIN1_"},"source":["#Standardizing the DataÂ¶\n","\n","Since PCA yields a feature subspace that maximizes the variance along the axes, it makes sense to standardize the data, especially, if it was measured on different scales.\n","\n","Standardization of a dataset is a common requirement for many machine learning estimators: they might behave badly if the individual feature do not more or less look like standard normally distributed data\n","\n","Notebook going over the importance of feature Scaling: http://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html#sphx-glr-auto-examples-preprocessing-plot-scaling-importance-py\n"]},{"cell_type":"code","metadata":{"id":"mAoSLQYOHnt5"},"source":["from sklearn.preprocessing import StandardScaler\n","#define scaler\n","scaler = StandardScaler()\n","\n","# Fit on training set only.\n"," \n","\n","# Apply transform to both the training set and the test set.\n","X_train = \n","X_test =  \n","\n","#X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P0KsvtHIImHM"},"source":["# In case you want to see how the scaled number would look like, you can uncomment below lines\n","#from scipy.stats import describe\n","#describe(X_train)[1]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8suV9hTYyN2_"},"source":["# Build PCA"]},{"cell_type":"code","metadata":{"id":"AdL_WHYHIqJn"},"source":["from sklearn.decomposition import PCA\n","\n","#define PCA with 0.9 variance to capture\n","pca = ....\n","\n","#use it to fit X_train\n","pca.fit(...)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x7daelXrJl3S"},"source":["# Look at components"]},{"cell_type":"code","metadata":{"id":"avBBGnfKJj2Q"},"source":["pca.n_components_\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IhCsTvUcJrVa"},"source":["#Apply the mapping (transform) to both the training set and the test set.\n","\n"]},{"cell_type":"code","metadata":{"id":"d0A_eeoIJnvm"},"source":["X_train = pca.put_the_right_function_here(put_the_right_data_here)\n","X_test = pca.put_the_right_function_here(put_the_right_data_here)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-hQFCo4JJ1Rz"},"source":["#Build a linear model and measure model fitting period."]},{"cell_type":"code","metadata":{"id":"TWGajY2pJzIP"},"source":["# Build a linear model using below parameters\n","\n","#solver = 'lbfgs'\n","# multi_class ='auto'\n","\n","#define the LogisticRegression model\n","logisticRegr = \n","\n","import datetime\n","start= datetime.datetime.now()\n","\n","# Fit the model\n","logisticRegr......\n","\n","end= datetime.datetime.now()\n","\n","print(end-start)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SzSIMXttJ_Zy"},"source":["\n","#logisticRegr.predict(X_train[0].reshape(1,-1))\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Jt4e5w9iKFNF"},"source":["#Measuring Model Performance"]},{"cell_type":"code","metadata":{"id":"SP9TM_6GKGMp"},"source":["score = logisticRegr.score(X_test, y_test)\n","print(score)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R3ED7CHoKL55"},"source":["#Replace numbers with yours\n","pd.DataFrame(data = [[1.00, 784, 48.94, .9158],\n","                     [.99, 541, 34.69, .9169],\n","                     [.95, 330, 13.89, .92],\n","                     [.90, 236, 10.56, .9168],\n","                     [.85, 184, 8.85, .9156]], \n","             columns = ['Variance Retained',\n","                      'Number of Components', \n","                      'Time (seconds)',\n","                      'Accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wTf4FVzqyyYo"},"source":[""],"execution_count":null,"outputs":[]}]}